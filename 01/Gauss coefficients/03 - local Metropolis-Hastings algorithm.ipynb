{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recovering Gauss coefficients by (local) Metropolis-Hastings sampling\n",
    "\n",
    "In this notebook, we compute the posterior distribution for the geomagnetic problem using Metropolis-Hastings sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Python packages and figure embellishments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Python packages.\n",
    "import magnetic as magnetic\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Set some parameters to make plots nicer.\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "\n",
    "# Set specific random seed to make simulations comparable.\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Input parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation points at the surface of the Earth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observation points.\n",
    "theta_obs=np.pi*np.random.rand(20)\n",
    "phi_obs=2.0*np.pi*np.random.rand(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gauss coefficients to include (to compute artificial and trial data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum degree.\n",
    "ell_max=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metropolis-Hastings parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proposal radius, step length.\n",
    "sigma=200.0\n",
    "\n",
    "# Number of Metropolis-Hastings samples.\n",
    "N=10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Initialisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the Gauss coefficients from the IGRF13 model. These will be used as ground-thruth parameters that we try to estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Gauss coefficients from IGRF13.\n",
    "g_igrf13,h_igrf13=magnetic.read_coefficients(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To accelerate the evaluation of the forward model, we precompute the Schmidt quasi-normalised associated Legendre functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pnmi=magnetic.Pnmi(theta_obs,ell_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute artificial observations for a chosen set of Gauss coefficients and synthesise the magnetic field from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the magnetic field values for the observation points.\n",
    "d_obs=magnetic.B(phi_obs,theta_obs,g_igrf13,h_igrf13,Pnmi,ell_max=ell_max)\n",
    "\n",
    "# Compute magnetic field for longitude and colatitude arrays.\n",
    "theta=np.arange(0.0,np.pi,0.05)\n",
    "phi=np.arange(0.0,2.0*np.pi,0.05)\n",
    "\n",
    "d_plot=magnetic.B_field(phi,theta,g_igrf13,h_igrf13,ell_max=ell_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the ground-truth magnetic field and the observation points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot radial component of the magnetic field.\n",
    "colat,lon=np.meshgrid(phi,theta)\n",
    "\n",
    "plt.subplots(1, figsize=(22,10))\n",
    "plt.gca().invert_yaxis()\n",
    "plt.pcolor(180.0*colat/np.pi,180.0*lon/np.pi,d_plot, cmap=plt.cm.get_cmap('Greys'))\n",
    "plt.colorbar()\n",
    "plt.contour(180.0*colat/np.pi,180.0*lon/np.pi,d_plot, colors='k')\n",
    "plt.plot(180.0*phi_obs/np.pi,180.0*theta_obs/np.pi,'ro',markersize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('longitude [°]',labelpad=15)\n",
    "plt.ylabel('colatitude [°]',labelpad=15)\n",
    "plt.title('magnetic field, radial component',pad=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before actually sampling the posterior distribution, we need to choose an initial location of the random walker. This can be done entirely randomly or already with some prior idea about useful parameters in mind. The performance of the sampler will depend on how well the initial position is chosen. (It will mostly affect the length of the burn-in phase.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial values.\n",
    "g=np.zeros(np.shape(g_igrf13))\n",
    "h=np.zeros(np.shape(h_igrf13))\n",
    "\n",
    "for i in range(1,ell_max+1):\n",
    "    for j in range(0,i+1):\n",
    "        \n",
    "        # Totally random selection of the initial model parameters.\n",
    "        #g[i,j]=5000.0*np.random.randn()\n",
    "        #h[i,j]=5000.0*np.random.randn()\n",
    "        \n",
    "        # Selection of initial model parameters near the ground-truth values.\n",
    "        g[i,j]=g_igrf13[i,j]+sigma*np.random.randn()\n",
    "        h[i,j]=h_igrf13[i,j]+sigma*np.random.randn()\n",
    "\n",
    "# Evaluate initial probability density.\n",
    "rho=magnetic.log_posterior(d_obs,phi_obs,theta_obs,g,h,Pnmi,ell_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid excessive storage requirements, we will only store all samples for two of the model parameters. The corresponding vectors and the number of accepted moves are initialised below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise number of accepted models.\n",
    "accept=0\n",
    "\n",
    "# Initialise arrays for the collection of samples.\n",
    "s1=[]\n",
    "s2=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform the actual random walk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise proposal vectors.\n",
    "g_prop=np.zeros(np.shape(g_igrf13))\n",
    "h_prop=np.zeros(np.shape(h_igrf13))\n",
    "\n",
    "t1=time.time()\n",
    "\n",
    "# Iterate.\n",
    "for it in range(0,N):\n",
    "    \n",
    "    for n in range(1,ell_max+1):\n",
    "        for m in range(0,n+1):\n",
    "            g_prop[n,m]=g[n,m]+sigma*np.random.randn()\n",
    "            h_prop[n,m]=h[n,m]+sigma*np.random.randn()\n",
    "            \n",
    "    # Evaluate probability of the proposal.\n",
    "    rho_prop=magnetic.log_posterior(d_obs,phi_obs,theta_obs,g_prop,h_prop,Pnmi,ell_max=ell_max)\n",
    "    \n",
    "    # Compute Metropolis ratio.\n",
    "    r=np.exp(rho_prop-rho)\n",
    "    \n",
    "    # Evaluate Metropolis rule\n",
    "    if r>np.random.rand():\n",
    "        # Make move to proposed position.\n",
    "        g=g_prop.copy()\n",
    "        h=h_prop.copy()\n",
    "        rho=rho_prop\n",
    "        # Increase number of accepted models.\n",
    "        accept+=1\n",
    "    \n",
    "    # Collect the samples.\n",
    "    # Here you may change the model parameters that are being considered.\n",
    "    s1.append(g[2,1])\n",
    "    s2.append(g[1,1])\n",
    "        \n",
    "t2=time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Output and analysis\n",
    "\n",
    "Following the sampling, we plot the results and perform some analyses. We start with the acceptance rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceptance rate.\n",
    "print('acceptance rate: %f ' % (accept/N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trace plots of the two selected model parameters. They should look like a hairy caterpillar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Trace plots.\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(s1,'k',linewidth=2)\n",
    "plt.xlim([0,N])\n",
    "plt.grid()\n",
    "plt.xlabel('samples',labelpad=15)\n",
    "plt.title('trace plot parameter 1',pad=15)\n",
    "plt.savefig('MH_traceplot_1.pdf')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(s2,'k',linewidth=2)\n",
    "plt.xlim([0,N])\n",
    "plt.grid()\n",
    "plt.xlabel('samples',labelpad=15)\n",
    "plt.title('trace plot parameter 2',pad=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto-correlation functions and derived from them, the effective sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-correlations.\n",
    "cc1=np.correlate(s1-np.mean(s1),s1-np.mean(s1),'full')/np.sum((s1-np.mean(s1))**2)\n",
    "cc1=cc1[N-1:]\n",
    "\n",
    "cc2=np.correlate(s2-np.mean(s2),s2-np.mean(s2),'full')/np.sum((s2-np.mean(s2))**2)\n",
    "cc2=cc2[N-1:]\n",
    "\n",
    "# Estimate of the effective sample size (Gelman et al., 2013).\n",
    "Neff1=0.0\n",
    "for i in range(N-1):\n",
    "    if (cc1[i]+cc1[i+1]>0.0):\n",
    "        Neff1+=cc1[i]\n",
    "        \n",
    "Neff1=N/(1.0+2.0*Neff1)\n",
    "print('effective sample size (parameter 1): %f' % Neff1)\n",
    "\n",
    "Neff2=0.0\n",
    "for i in range(N-1):\n",
    "    if (cc2[i]+cc2[i+1]>0.0):\n",
    "        Neff2+=cc2[i]\n",
    "        \n",
    "Neff2=N/(1.0+2.0*Neff2)\n",
    "print('effective sample size (parameter 2): %f' % Neff2)\n",
    "\n",
    "# Plot autocorrelation function.\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(cc1[0:N],'k',linewidth=2)\n",
    "plt.xlabel('samples',labelpad=15)\n",
    "plt.xlim([0,N])\n",
    "plt.title('auto-correlation (parameter 1)',pad=15)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(cc2[0:N],'k',linewidth=2)\n",
    "plt.xlabel('samples',labelpad=15)\n",
    "plt.xlim([0,N])\n",
    "plt.title('auto-correlation (parameter 2)',pad=15)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-D marginals of the two selected model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "n, bins, patches = plt.hist(s1, 20, density=True, facecolor='k', alpha=1.0)\n",
    "plt.xlabel('parameter 1',labelpad=15)\n",
    "plt.title('1-D marginal (parameter 1)',pad=15)\n",
    "plt.grid()\n",
    "plt.xlim([0.0,6000.0])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "n, bins, patches = plt.hist(s2, 20, density=True, facecolor='k', alpha=1.0)\n",
    "plt.xlabel('parameter 2',labelpad=15)\n",
    "plt.title('1-D marginal (parameter 2)',pad=15)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-D marginal of the selected model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.hist2d(s1, s2, bins=20, density=True, cmap='Greys')\n",
    "plt.xlabel('parameter 1',labelpad=15)\n",
    "plt.ylabel('parameter 2',labelpad=15)\n",
    "plt.title('1-D marginal (parameter 1)',pad=15)\n",
    "plt.xlim([1500.0,4500.0])\n",
    "plt.ylim([-3000.0,0.0])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Exercises\n",
    "\n",
    "**Exercise 1**: Estimate by trial and error a search radius $\\sigma$ that maximises the effective sample size. Over how many samples is the sample chain correlated (just roughly)?\n",
    "\n",
    "**Exercise 2**: With this nearly optimal choice of $\\sigma$, investigate the appearance of the posterior marginals as a function of the number of samples. How many samples would you recommend to obtain a 'useful' result.\n",
    "\n",
    "**Exercise 3**: Keeping $\\sigma$ and the total number of samples as above, (**a**) reduce the number of observations to 10 and (**b**) increase it to 50. How does this affect the quality of your inference? How would you measure quality?\n",
    "\n",
    "**Exercise 4**: In the examples above, the initial model parameter values, i.e., the starting position of the random walker, is chosen somewhat optimistically near the ground-thruth values. Investigate the more realistic case where the initial values are chosen completely randomly. What is the effect on the length of the burn-in phase? Modify the code such that the samples of the burn-in phase are ignored in the calculation of the posterior marginals."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
