{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recovering Gauss coefficients by HMC sampling\n",
    "\n",
    "In this notebook, we compute the posterior distribution for the geomagnetic problem using the Hamiltonian Monte Carlo (HMC) algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Python packages and figure embellishments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Python packages.\n",
    "import magnetic as magnetic\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set some parameters to make plots nicer.\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "\n",
    "# Set specific random seed to make simulations comparable.\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Input parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation points at the surface of the Earth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observation points.\n",
    "theta_obs=np.pi*np.random.rand(20)\n",
    "phi_obs=2.0*np.pi*np.random.rand(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gauss coefficients to include (to compute artificial and trial data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum degree.\n",
    "ell_max=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HMC sampling parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of leap-frog steps.\n",
    "Nt=8\n",
    "\n",
    "# Leap-frog time increment.\n",
    "dt=150.0\n",
    "\n",
    "# Number of HMC samples.\n",
    "N=10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Initialisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the Gauss coefficients from the IGRF13 model. These will be used as ground-thruth parameters that we try to estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Gauss coefficients from IGRF13.\n",
    "g_igrf13,h_igrf13=magnetic.read_coefficients(verbose=False)\n",
    "\n",
    "Nc=np.shape(g_igrf13)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To accelerate the evaluation of the forward model, we precompute the Schmidt quasi-normalised associated Legendre functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pnmi=magnetic.Pnmi(theta_obs,ell_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute artificial observations for a chosen set of Gauss coefficients and synthesise the magnetic field from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the magnetic field values for the observation points.\n",
    "d_obs=magnetic.B(phi_obs,theta_obs,g_igrf13,h_igrf13,Pnmi,ell_max=ell_max)\n",
    "\n",
    "# Compute magnetic field for longitude and colatitude arrays.\n",
    "theta=np.arange(0.0,np.pi,0.05)\n",
    "phi=np.arange(0.0,2.0*np.pi,0.05)\n",
    "\n",
    "d_plot=magnetic.B_field(phi,theta,g_igrf13,h_igrf13,ell_max=ell_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the ground-truth magnetic field and the observation points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot radial component of the magnetic field.\n",
    "colat,lon=np.meshgrid(phi,theta)\n",
    "\n",
    "plt.subplots(1, figsize=(22,10))\n",
    "plt.gca().invert_yaxis()\n",
    "plt.pcolor(180.0*colat/np.pi,180.0*lon/np.pi,d_plot, cmap=plt.cm.get_cmap('Greys'))\n",
    "plt.colorbar()\n",
    "plt.contour(180.0*colat/np.pi,180.0*lon/np.pi,d_plot, colors='k')\n",
    "plt.plot(180.0*phi_obs/np.pi,180.0*theta_obs/np.pi,'ro',markersize=10)\n",
    "plt.grid()\n",
    "plt.xlabel('longitude [°]',labelpad=15)\n",
    "plt.ylabel('colatitude [°]',labelpad=15)\n",
    "plt.title('magnetic field, radial component',pad=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Sampling\n",
    "\n",
    "Before actually sampling the posterior distribution, we need to choose an initial location of the random walker. This can be done entirely randomly or already with some prior idea about useful parameters in mind. The performance of the sampler will depend on how well the initial position is chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial model vector. We place g coefficients into m[0,:,:] and h coefficients into m[1,:,:].\n",
    "m=np.zeros((2,Nc,Nc))\n",
    "\n",
    "# Selection of initial model parameters near the ground-truth values.\n",
    "for i in range(0,ell_max+1):\n",
    "    for j in range(0,i+1):\n",
    "        m[0,i,j]=g_igrf13[i,j]+200.0*np.random.randn()\n",
    "        m[1,i,j]=h_igrf13[i,j]+200.0*np.random.randn()\n",
    "\n",
    "# Evaluate initial probability density.\n",
    "rho=magnetic.log_posterior(d_obs,phi_obs,theta_obs,m[0,:,:],m[1,:,:],Pnmi,ell_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E=0.0\n",
    "\n",
    "# Add energy contributions from included degrees.\n",
    "for i in range(0,ell_max+1):\n",
    "\tfor j in range(0,i+1):\n",
    "\t\tE+=(m[0,i,j]**2+m[1,i,j]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid excessive storage requirements, we will only store all samples for two of the model parameters. The corresponding vectors and the number of accepted moves are initialised below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise number of accepted models.\n",
    "accept=0\n",
    "\n",
    "# Initialise arrays for the collection of samples.\n",
    "s1=[]\n",
    "s2=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=time.time()\n",
    "\n",
    "# Loop over samples.\n",
    "for it in range(0,N):\n",
    "    \n",
    "    # Choose a random momentum vector from the standard normal distribution.\n",
    "    p=np.random.randn(2*Nc*Nc).reshape(2,Nc,Nc)\n",
    "    \n",
    "    # Evaluate energies.\n",
    "    U=-magnetic.log_posterior(d_obs,phi_obs,theta_obs,m[0,:,:],m[1,:,:],Pnmi,ell_max)\n",
    "    K=0.5*np.dot(p.flatten(),p.flatten())\n",
    "    H=U+K\n",
    "    \n",
    "    # Leap-frog iteration. ====================================================\n",
    "    \n",
    "    m_prop=m.copy()\n",
    "    p_prop=p.copy()\n",
    "    \n",
    "    J=-magnetic.grad_posterior(d_obs,phi_obs,theta_obs,m[0,:,:],m[1,:,:],Pnmi,ell_max)\n",
    "    \n",
    "    for k in range(Nt):\n",
    "        \n",
    "        p_prop=p_prop-0.5*dt*J\n",
    "        m_prop=m_prop+dt*p_prop\n",
    "        J=-magnetic.grad_posterior(d_obs,phi_obs,theta_obs,m_prop[0,:,:],m_prop[1,:,:],Pnmi,ell_max)\n",
    "        p_prop=p_prop-0.5*dt*J\n",
    "        \n",
    "    # =========================================================================\n",
    "    \n",
    "    # Evaluate new energies.\n",
    "    U_prop=-magnetic.log_posterior(d_obs,phi_obs,theta_obs,m_prop[0,:,:],m_prop[1,:,:],Pnmi,ell_max)\n",
    "    K_prop=0.5*np.dot(p_prop.flatten(),p_prop.flatten())\n",
    "    H_prop=U_prop+K_prop\n",
    "    \n",
    "    # Evaluate HMC Metropolis rule in logarithmic form.\n",
    "    r=np.minimum(0.0,H-H_prop)\n",
    "    if r>=np.log(np.random.random(1)):\n",
    "        # Make move to proposed position.\n",
    "        m=m_prop.copy()\n",
    "        H=H_prop\n",
    "        # Increase number of accepted models.\n",
    "        accept+=1\n",
    "    \n",
    "    # Collect the samples.\n",
    "    # Here you may change the model parameters that are being considered.\n",
    "    s1.append(m[0,2,1])\n",
    "    s2.append(m[0,1,1])\n",
    "    \n",
    "t2=time.time()\n",
    "print('elapsed time: %f s' % (t2-t1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Output and analysis\n",
    "\n",
    "Following the sampling, we plot the results and perform some analyses. We start with the acceptance rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceptance rate.\n",
    "print('acceptance rate: %f ' % (accept/N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trace plots of the two selected model parameters. They should look like a hairy caterpillar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Trace plots.\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(s1,'k',linewidth=2)\n",
    "plt.xlim([0,N])\n",
    "plt.grid()\n",
    "plt.xlabel('samples',labelpad=15)\n",
    "plt.title('trace plot parameter 1',pad=15)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(s2,'k',linewidth=2)\n",
    "plt.xlim([0,N])\n",
    "plt.grid()\n",
    "plt.xlabel('samples',labelpad=15)\n",
    "plt.title('trace plot parameter 2',pad=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto-correlation functions and derived from them, the effective sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-correlations.\n",
    "cc1=np.correlate(s1-np.mean(s1),s1-np.mean(s1),'full')/np.sum((s1-np.mean(s1))**2)\n",
    "cc1=cc1[N-1:]\n",
    "\n",
    "cc2=np.correlate(s2-np.mean(s2),s2-np.mean(s2),'full')/np.sum((s2-np.mean(s2))**2)\n",
    "cc2=cc2[N-1:]\n",
    "\n",
    "# Estimate of the effective sample size (Gelman et al., 2013).\n",
    "Neff1=0.0\n",
    "for i in range(N-1):\n",
    "    if (cc1[i]+cc1[i+1]>0.0):\n",
    "        Neff1+=cc1[i]\n",
    "        \n",
    "Neff1=N/(1.0+2.0*Neff1)\n",
    "print('effective sample size (parameter 1): %f' % Neff1)\n",
    "\n",
    "Neff2=0.0\n",
    "for i in range(N-1):\n",
    "    if (cc2[i]+cc2[i+1]>0.0):\n",
    "        Neff2+=cc2[i]\n",
    "        \n",
    "Neff2=N/(1.0+2.0*Neff2)\n",
    "print('effective sample size (parameter 2): %f' % Neff2)\n",
    "\n",
    "# Plot autocorrelation function.\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(cc1[0:N],'k',linewidth=2)\n",
    "plt.xlabel('samples',labelpad=15)\n",
    "plt.xlim([0,N])\n",
    "plt.title('auto-correlation (parameter 1)',pad=15)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(cc2[0:N],'k',linewidth=2)\n",
    "plt.xlabel('samples',labelpad=15)\n",
    "plt.xlim([0,N])\n",
    "plt.title('auto-correlation (parameter 2)',pad=15)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-D marginals of the two selected model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "n, bins, patches = plt.hist(s1, 20, density=True, facecolor='k', alpha=1.0)\n",
    "plt.xlabel('parameter 1',labelpad=15)\n",
    "plt.title('1-D marginal (parameter 1)',pad=15)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "n, bins, patches = plt.hist(s2, 20, density=True, facecolor='k', alpha=1.0)\n",
    "plt.xlabel('parameter 2',labelpad=15)\n",
    "plt.title('1-D marginal (parameter 2)',pad=15)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-D marginal of the selected model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.hist2d(s1, s2, bins=20, density=True, cmap='Greys')\n",
    "plt.xlabel('parameter 1',labelpad=15)\n",
    "plt.ylabel('parameter 2',labelpad=15)\n",
    "plt.title('1-D marginal (parameter 1)',pad=15)\n",
    "plt.xlim([1500.0,4500.0])\n",
    "plt.ylim([-3000.0,0.0])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Exercises\n",
    "\n",
    "**Exercise 1**: Include actual random errors in the artificial observed data *d_obs*. Make sure that these are in accord with the observed error standard deviation *sigma_D* in *magnetic.py*. Repeat the HMC sampling for a range of different standard deviations. Describe your observations.\n",
    "\n",
    "**Exercise 2**: Keeping the leap-frog time increment fixed at *dt=150*, explore the relation between the number of leap-frog steps *Nt*, the acceptance rate, and the effective sample size. Choose *Nt* values of 1, 4, 8, 12 and 16. Explain your observation.\n",
    "\n",
    "**Exercise 3**: What is the maximum effective sample fraction that you can achieve by tuning *dt* and *Nt*? How does this compare to the optimal tuning of MALA and the Metropolis-Hastings algorithm, where *sigma* is the only tuning parameter?\n",
    "\n",
    "**Exercise 4**: Increase the maximum harmonic degree, *ell_max* to 13, which is the maximum degree included in the IGRF13 model of the current geomagnetic field. How do the number of leap-frog steps *Nt* and the time increment *dt* need to be adjusted in order to achieve an acceptance rate of around 50 %?\n",
    "\n",
    "**Exercise 5**: Return to the MALA notebook and also set *ell_max* to 13. Tune the parameter *sigma* such that the acceptance rate is also around 50 %. Compare the trace plots for the HMC and MALA samplers. How do the two algorithms explore model space? Explain your observation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
