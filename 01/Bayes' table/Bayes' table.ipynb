{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes' table\n",
    "\n",
    "In their 1763 essay (Bayes, T & Price, R., 1763. *An essay toward solving a problem in the doctrine of chances.* Phil. Trans. R. Sac. London, 53, 370-418.), Thomas Bayes and Richard Price consider a simple thought experiment in order to illustrate basic concepts of what we now call Bayesian inference. The setup consists of a perfectly planar table extending from $x=0$ to $x=l_x$ in $x$-direction and from $y=0$ to $y=l_y$ in $y$-direction. \n",
    "\n",
    "The experiment starts by throwing a ball $A$ onto the table. It comes to rest at some random point $(x_A,y_A)$. This\n",
    " point divides the table into two domains, $D_l$ to the left and $D_r$ to the right. Then, the experimenter throws a second ball, $B$, which lands on another point $(x_B,y_B)$. Subsequently, the second ball is thrown again, and again, ..., $N$ times in total.\n",
    " Next to the experimenter stands an observer who cannot see the table. The experimenter merely tells the observer if the second ball $B$ has landed inside the left domain $D_l$, an event that we shall call $L$.\n",
    " \n",
    "Initially, the observer has no information on where $A$ has landed, nor can he make any prediction on where the next $B$ is likely to land. But could he make any quantitative predictions based\n",
    " on the information conveyed to him by the experimenter?\n",
    " \n",
    "In fact, after observing event $L$ for a total of $p$ times in $N$ experiments, we find that the conditional probability that ball $A$ landed at position $x_A$ is given by\n",
    "\n",
    "\\begin{equation}\n",
    "P(x_A|p) = k\\,P(p|x_A) P(x_A) = k\\, \\begin{pmatrix} N \\\\ p \\end{pmatrix} \\left( \\frac{x_A}{l_x} \\right)^p \\left( 1 - \\frac{x_A}{l_x} \\right)^{N-p}\\, \\frac{\\Delta x}{l_x}\\,.\n",
    "\\end{equation}\n",
    "\n",
    "First, we will visualise this conditional probability as a function of the total number of experiments $N$, and the number of times that event $L$ has been observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import some Python packages\n",
    "\n",
    "We begin by importing some Python packages for special functions (e.g., the factorial) and for plotting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Python packages.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special as special\n",
    "\n",
    "# Set some parameters to make plots nicer.\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams.update({'font.size': 20})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup\n",
    "\n",
    "We first need to define a couple of input parameters, including $N$, $p$, the discretised spacing along the $x$-axis, $\\Delta x$, and the positions along the $x$-axis, $x_A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=20    # Total number of experiments.\n",
    "p=9     # Observed number of event L.\n",
    "\n",
    "dx=0.025                        # Spacing of the x-axis.\n",
    "x_A=np.arange(0.0,1.0+dx,dx)    # Positions x_A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Computation of the posterior\n",
    "\n",
    "Next, we compute the posterior distribution given in the equation above and plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute posterior. ----------------------------------------\n",
    "\n",
    "P=np.zeros(len(x_A))\n",
    "\n",
    "P=float(special.binom(N,p))*np.power(x_A,p)*np.power(1.0-x_A,N-p)*dx\n",
    "P=P/np.sum(P)\n",
    "\n",
    "# Visualisation. --------------------------------------------\n",
    "\n",
    "plt.subplots(figsize=(20, 10))\n",
    "plt.plot(x_A,P,'ko',markersize=7)\n",
    "plt.plot(x_A,P,'k--',linewidth=1.5)\n",
    "plt.grid()\n",
    "plt.xlabel(r'$x_A$')\n",
    "plt.ylabel(r'$P(x_A|p)$')\n",
    "plt.title('posterior for position $x_A$')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Predictions of future observations\n",
    "\n",
    "What apparently fascinated Price and Bayes most is the ability to make quantitative predictions of future events. Indeed, the probability of observing $L$ given that is has been observed $p$ times before, is\n",
    "\\begin{equation}\n",
    "P(L | p) = \\sum_{x_A} k\\, \\begin{pmatrix} N \\\\ p \\end{pmatrix} \\left( \\frac{x_A}{l_x} \\right)^{p+1} \\left( 1 - \\frac{x_A}{l_x} \\right)^{N-p}\\, \\frac{\\Delta x}{l_x}\\,.\n",
    "\\end{equation}\n",
    "We compute and visualise this probability distribution below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute posterior marginal. -------------------------------\n",
    "\n",
    "P=np.zeros(len(x_A))\n",
    "PL=np.zeros(N+1)\n",
    "\n",
    "for p in range(N+1):\n",
    "\n",
    "    P=float(special.binom(N,p))*np.power(x_A,p)*np.power(1.0-x_A,N-p)*dx\n",
    "    P=P/np.sum(P)\n",
    "    P=P*x_A\n",
    "    PL[p]=sum(P)\n",
    "\n",
    "# Visualisation. --------------------------------------------\n",
    "    \n",
    "plt.plot(range(N+1),PL,'ko',markersize=7)\n",
    "plt.plot(range(N+1),PL,'k--',linewidth=1.5)\n",
    "plt.grid()\n",
    "plt.ylim((0.0,1.0))\n",
    "plt.xlabel(r'$p$')\n",
    "plt.ylabel(r'$P(L|p)$')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.savefig('N20.pdf',format='pdf')\n",
    "plt.close()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
