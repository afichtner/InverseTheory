{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMC in ND with F-BFGS autotuning of the mass matrix\n",
    "\n",
    "This notebook implements an autotuning HMC for an N-dimensional distribution based on factorised BFGS (F-BFGS) updating of the (inverse) Hessian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "\n",
    "import testfunctions\n",
    "import samplestatistics\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times\"\n",
    "plt.rcParams.update({'font.size': 50})\n",
    "plt.rcParams['xtick.major.pad']='12'\n",
    "plt.rcParams['ytick.major.pad']='12'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Input\n",
    "\n",
    "We first define several input parameters, including the model space dimension, the total number of samples, the number of leapfrog timesteps, and the length of the timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import input_parameters\n",
    "reload(input_parameters)\n",
    "test_function,dim,N,Nit,dt,m0,Minv,autotune,ell,update_interval,preco,S0_min,plot_interval,dimension1,dimension2,m1_min,m1_max,m2_min,m2_max=input_parameters.input_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Class for F-BFGS autotuning\n",
    "\n",
    "This class takes care of the factorised BFGS updating. The class must be initialised with the first model and the first gradient. The *update* function then takes the next model and gradient, and computes updates of the approximate matrix factor $\\mathbf{S}$, of the approximate Hessian $\\mathbf{H}$, and of the approximate inverse Hessian $\\mathbf{H}^{-1}$.\n",
    "\n",
    "**Call to caution**: There is an experimental component in this class. In principle, BFGS updates can only be made when $\\mathbf{s}_k^T\\mathbf{y}>0$. However, when this quantity is very small, the resulting Hessian approximation may still be close to singular. Empirically, it is better for stability to choose $\\mathbf{s}_k^T\\mathbf{y}>\\gamma$, with some tuning parameter $\\gamma>0$. For many examples, $\\gamma=2$ works very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fbfgs:\n",
    "    \n",
    "    def __init__(self,dim,Minv,m,g):\n",
    "        \"\"\"\n",
    "        Initialise the BFGS iteration.\n",
    "        \n",
    "        :param dim: number of model-space dimensions\n",
    "        :param Minv: initial inverse mass matrix (must be diagonal)\n",
    "        :param m: current model vector\n",
    "        :param g: current gradient\n",
    "        \"\"\"\n",
    "        \n",
    "        self.dim=dim   # Model space dimension.\n",
    "        self.Hinv=Minv   # Initial (current) estimate of the inverse Hessian H^{-1}.\n",
    "        \n",
    "        # Initial (current) matrix factor S and estimate of the Hessian\n",
    "        \n",
    "        self.S=np.identity(dim)   \n",
    "        self.H=np.identity(dim)   \n",
    "        \n",
    "        for i in range(dim):\n",
    "            self.H[i,i]=1.0/Minv[i,i]\n",
    "            self.S[i,i]=1.0/np.sqrt(Minv[i,i])\n",
    "        \n",
    "        self.logdet=0.0   # Initial (current) logarithm of the determinant of the Hessian H.\n",
    "        self.m=m   # Initial (current) model.\n",
    "        self.g=g   # Initial (current) gradient.\n",
    "        self.I=np.identity(dim)   # Identity matrix. \n",
    "        \n",
    "    def update(self,m,g):\n",
    "        \"\"\"\n",
    "        Update BFGS matrix and its factorised form.\n",
    "        \n",
    "        :param m: current model vector\n",
    "        :param g: current gradient\n",
    "        \"\"\"\n",
    "        \n",
    "        # Compute differences and update vectors.\n",
    "        s=m-self.m\n",
    "        y=g-self.g\n",
    "        \n",
    "        check=np.dot(s,y)\n",
    "        #print(check)\n",
    "        \n",
    "        # Do nothing unless rho is positive.\n",
    "        if check>2.0:\n",
    "            \n",
    "            # Set new to current vectors.\n",
    "            self.m=m\n",
    "            self.g=g\n",
    "            \n",
    "            # Precompute inverse Hessian-vector product.\n",
    "            Hinv_y=np.dot(self.Hinv,y)\n",
    "            \n",
    "            # Auxiliary scalars.\n",
    "            rho=1.0/np.dot(s,y)\n",
    "            gamma2=rho**2 * np.dot(y,Hinv_y) + rho\n",
    "            beta=gamma2 * np.dot(s,np.dot(self.H,s))\n",
    "            theta=-np.sqrt(rho/(beta*gamma2))\n",
    "        \n",
    "            # Auxiliary vectors a, b, and u, v.\n",
    "            a=np.sqrt(gamma2)*s\n",
    "            b=(rho/np.sqrt(gamma2))*Hinv_y\n",
    "            u=a\n",
    "            v=-np.dot(self.H,b+theta*a)\n",
    "            \n",
    "            # Update inverse Hessian estimate Hinv. \n",
    "            alpha=1.0/(1.0+np.dot(u,v))\n",
    "            Hinv_v=np.dot(self.Hinv,v)\n",
    "            self.Hinv=self.Hinv+np.tensordot(Hinv_v,u,axes=0)+np.tensordot(u,Hinv_v,axes=0)+np.tensordot(u,u,axes=0)*np.dot(v,Hinv_v)\n",
    "        \n",
    "            # Update Hessian estimate H.\n",
    "            H_u=np.dot(self.H,u)\n",
    "            self.H=self.H-alpha*np.tensordot(H_u,v,axes=0)-alpha*np.tensordot(v,H_u,axes=0)+(alpha**2)*np.tensordot(v,v,axes=0)*np.dot(u,H_u)\n",
    "        \n",
    "            # Update factor S.\n",
    "            ST_u=np.dot(self.S.transpose(),u)\n",
    "            self.S=self.S-alpha*np.tensordot(v,ST_u,axes=0)\n",
    "            \n",
    "            # Update determinant of S.\n",
    "            self.logdet+=np.log(alpha**2)\n",
    "            \n",
    "        else: \n",
    "            rhoinv=np.dot(s,y)\n",
    "            print('F-BFGS check failed (1/rho=%f)' % rhoinv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Leapfrog integrator\n",
    "\n",
    "For clarity, we define the leap-frog integrator as a separate function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leapfrog(m,p,Nt,dt,Minv,fct,plot=False):\n",
    "    \n",
    "    # Plot probability density in the background.\n",
    "    if plot:\n",
    "        fct.plotU(dim,dimension1,dimension2,m1_min,m1_max,m2_min,m2_max)\n",
    "        plt.plot(m[dimension1],m[dimension2],'bo',MarkerSize=15)\n",
    "    \n",
    "    # Evaluate initial gradient.\n",
    "    J=fct.J(m)\n",
    "    \n",
    "    # Determine randomised integration length.\n",
    "    Nti=np.int(Nt*(1.0-0.5*np.random.rand()))\n",
    "    \n",
    "    # Leapfrog integration.\n",
    "    for k in range(Nti):\n",
    "        \n",
    "        if plot: m_old=m.copy()\n",
    "        \n",
    "        p=p-0.5*dt*J\n",
    "        m=m+dt*Minv.dot(p)\n",
    "        J=fct.J(m)\n",
    "        p=p-0.5*dt*J\n",
    "        \n",
    "        # Plot trajectory segment.\n",
    "        if plot: \n",
    "            if k==0: print('number of time steps: %d' % Nti)\n",
    "            plt.plot([m_old[dimension1],m[dimension1]],[m_old[dimension2],m[dimension2]],'r',linewidth=3)\n",
    "            plt.plot(m[dimension1],m[dimension2],'kx',markersize=15)\n",
    "        \n",
    "    return m, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. HMC initialisations\n",
    "\n",
    "Before running the actual HMC sampler, we perform several initialisations. This includes the test function class, the first random model $\\mathbf{m}$, and the corresponding gradient of the potential energy $\\mathbf{g}=\\nabla U$. With this, we can initialise the F-BFGS class, which takes $\\mathbf{m}$ and $\\mathbf{g}$ as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation. =============================================================\n",
    "\n",
    "# Test function class.\n",
    "fct=testfunctions.f(dim,test_function)\n",
    "\n",
    "# Number of accepted models.\n",
    "accept=0\n",
    "\n",
    "# Randomly chosen initial model.\n",
    "m=m0\n",
    "\n",
    "# Posterior statistics.\n",
    "s=samplestatistics.stats(dimension1,dimension2,N)\n",
    "s.get(m,0.0,0)\n",
    "\n",
    "# Initialise BFGS matrix.\n",
    "g=fct.J(m)\n",
    "M=fbfgs(dim,Minv,m,g)\n",
    "\n",
    "# Specific matrix elements for monitoring.\n",
    "m11=Minv[dimension1,dimension1]*np.ones(N)\n",
    "m22=Minv[dimension2,dimension2]*np.ones(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run HMC\n",
    "\n",
    "We finally run the HMC sampler. In each iteration, we first produce radom momenta $\\mathbf{p}$ from a normal distribution with covariance chosen to be the F-BFGS-updated inverse mass matrix $\\mathbf{M}^{-1}$, which is defined to be the inverse Hessian $\\mathbf{H}^{-1}$ of the potential energy $U$. \n",
    "\n",
    "Using the mass matrix, we compute energies and run a leapfrog iteration to solve Hamilton's equations. Following this, we compute the energies of the proposed model and evaluate the modified Metropolis rule (in logarithimic form, to avoid over- or under-flow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "accept=0\n",
    "start=time.time()\n",
    "\n",
    "for it in range(N-1):\n",
    "\n",
    "    # Randomly choose momentum.\n",
    "    p=np.random.randn(dim)\n",
    "    p=M.S.dot(p)\n",
    "    \n",
    "    # Evaluate energies.\n",
    "    U=fct.U(m)\n",
    "    K=0.5*np.dot(p,np.dot(M.Hinv,p))\n",
    "    H=U+K\n",
    "    \n",
    "    # Check if models and trajectories should be plotted.\n",
    "    if (not it % plot_interval) and it>0: \n",
    "        plot=True\n",
    "        print('iteration: %d' % it)\n",
    "    else:\n",
    "        plot=False\n",
    "    \n",
    "    # Run leapfrog iteration.\n",
    "    m_new,p_new=leapfrog(m,p,Nit,dt,M.Hinv,fct,plot)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot proposed models.\n",
    "    if plot:\n",
    "        plt.subplots(1, figsize=(30,10))\n",
    "        plt.plot(m_new)\n",
    "        plt.xlabel('model parameter index')\n",
    "        plt.show()\n",
    "    \n",
    "    # Evaluate new energies.\n",
    "    U_new=fct.U(m_new)\n",
    "    K_new=0.5*np.dot(p_new,M.Hinv.dot(p_new))\n",
    "    H_new=U_new+K_new\n",
    "    \n",
    "    # Evaluate Metropolis rule in logarithmic form.\n",
    "    alpha=np.minimum(0.0,H-H_new)\n",
    "    #print(alpha)\n",
    "    if alpha>=np.log(np.random.rand(1)):\n",
    "        # Update model.\n",
    "        m=m_new\n",
    "        accept+=1\n",
    "        # Update BFGS matrix.\n",
    "        if autotune:\n",
    "            g=fct.J(m)\n",
    "            M.update(m,g)\n",
    "    \n",
    "    # Accumulate on-the-fly statistics\n",
    "    s.get(m,M.logdet,it+1)\n",
    "    m11[it+1]=M.Hinv[dimension1,dimension1]\n",
    "    m22[it+1]=M.Hinv[dimension2,dimension2]\n",
    "    \n",
    "stop=time.time()\n",
    "print('acceptance rate: %f (%d of %d samples)' % (np.float(accept)/np.float(N),accept,N))\n",
    "print('elapsed time: %f s' % (stop-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analyse results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1. Sample statistics collected on the fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2. Analysis of the mass matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.subplots(1, figsize=(20,20))\n",
    "plt.pcolor(Minv,cmap='Blues')\n",
    "plt.title('initial inverse mass matrix',pad=20)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.subplots(1, figsize=(20,20))\n",
    "plt.pcolor(M.Hinv,cmap='Blues')\n",
    "plt.title('final inverse mass matrix',pad=20)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.subplots(1, figsize=(20,20))\n",
    "plt.pcolor(M.S,cmap='RdBu')\n",
    "plt.title('final S',pad=20)\n",
    "c=np.max(np.abs(M.S))\n",
    "plt.clim([-c,c])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.subplots(1, figsize=(20,20))\n",
    "plt.pcolor(np.dot(M.S,M.S.transpose()),cmap='Blues')\n",
    "plt.title('final SS^T',pad=20)\n",
    "#c=np.max(np.abs(np.dot(M.S,M.S.transpose())))\n",
    "#plt.clim([-c,c])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.subplots(1, figsize=(20,10))\n",
    "plt.plot(np.diag(M.Hinv),'k',linewidth=4)\n",
    "plt.plot(np.diag(Minv),'r',linewidth=4)\n",
    "plt.xlabel('index')\n",
    "plt.title('diagonal of inverse mass matrix (final=black, initial=red)')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.subplots(1, figsize=(20,10))\n",
    "plt.plot(m11,'k',linewidth=4)\n",
    "plt.plot(m22,'r',linewidth=4)\n",
    "plt.xlabel('iteration')\n",
    "plt.title('diagonal elements (black=parameter1, red=parameter2)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
